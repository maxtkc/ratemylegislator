services:
  data-scraper:
    build:
      context: ./data-scraper
      dockerfile: Dockerfile
    container_name: ratemylegislator-data-scraper
    volumes:
      - ./data-scraper/data:/app/data
      - ./data-scraper/logs:/app/logs
      - ./data-scraper/src:/app/src  # For development
      - ./frontend/src/data:/app/export  # Export data directly to frontend
    environment:
      - PYTHONPATH=/app/src
      - DATABASE_URL=sqlite:///app/data/hawaii_legislature.db
      - EXPORT_DIR=/app/export
    restart: "no"  # Don't restart automatically - run on demand
    healthcheck:
      test: ["CMD", "python", "src/test_schema.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  frontend-dev:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    container_name: ratemylegislator-frontend-dev
    volumes:
      - ./frontend:/app
      - /app/node_modules  # Anonymous volume for node_modules
    environment:
      - NODE_ENV=development
    ports:
      - "3000:8000"  # Gatsby dev server runs on port 8000 inside container
    restart: unless-stopped
    command: ["npm", "run", "develop", "--", "--host", "0.0.0.0"]

  frontend-build:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: build
    container_name: ratemylegislator-frontend-build
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - ./frontend/public:/app/public  # Export built files
    environment:
      - NODE_ENV=production
    profiles:
      - build
    command: ["npm", "run", "build:github"]

  # Database service (for future PostgreSQL migration)
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: ratemylegislator-db
  #   environment:
  #     POSTGRES_DB: hawaii_legislature
  #     POSTGRES_USER: postgres
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   ports:
  #     - "5432:5432"
  #   restart: unless-stopped

volumes:
  # postgres_data:
  scraper_data:
  scraper_logs:
